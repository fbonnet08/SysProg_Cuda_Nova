
            # TODO: remove the the exit(rc) statement after the jsonn file have been done correctly
            #exit(rc)
            # TODO: once removed you may continue with the database pushing


        print (type(gpu_number))
        print(gpu_number)

                print('setting the use_gpu to :', use_gpu)
                print('setting the device number to:', gpu_number)


        print("use gpu  true oir false ---->: ", self.c.getUse_gpu())
        print("which gpu device number ---->: ", self.c.getSet_gpu())


    def get_platform(self):
        if sys.platform.startswith('linux'):
            return 'linux'
        elif sys.platform.startswith('win32'):
            return 'win32'
        elif sys.platform.startswith('cygwin'):
            return 'cygwin'
        elif sys.platform.startswith('darwin'):
            return 'darwin'
        else:
            return sys.platform





                    '''
                    for j in range(len(metaData[i][:])):
                    print("metaData["+str(i)+"] --->: ", metaData[i][j])

                    '''
                    #print(" idata['metaData'] --->: ", idata['metaData']['name'])



        start_key = "FILENAME"

        end_key = "END IONS"
        trigger_key = "Scan#: "   # "PEPMASS"
        # Replacement keys
        FEATURE_ID_key = "FEATURE_ID"
        SPECTRUMID_key = "SPECTRUMID"
        TAXONOMY_key = "TAXONOMY"
        SCANS_key = "SCANS"
        SCAN_ID_key = "SCAN_ID"
        LIBRARYQUALITY_key = "LIBRARYQUALITY"
        LIBRARY_QUALITY_key = "LIBRARY_QUALITY"
        CHARGE_key = "CHARGE"
        SMILES_key = "SMILES"
        NAME_key = "NAME"
        SYNNO_key = "SYNNO"






            # TODO: 5. Spectral data insert table
            #rc, tb_count = jsonSanner.get_TableCount_FromTable(json_data=json_data_table_count, table='spectral_data', silent=True)
            table_length = int(tb_count) + 1
            '''
            rc = self.MolRefAnt_DB_POstGresSQLWritter_Spectral_data(file_sql,
                                                                    queryMsSQL, cursor,
                                                                    jsonfile_content_dict_lst[ifile],
                                                                    jsonfile_content_key[ifile],
                                                                    jsonfile_content_value[ifile],
                                                                    database, table, table_length)
            '''
            # TODO: 6. insert compound from spectral_id
            rc, tb_count = jsonSanner.get_TableCount_FromTable(json_data=json_data_table_count, table='compound', silent=True)
            table_length = int(tb_count) + 1
            #print("tb_count --->: ", tb_count)


            # TODO: 7. insert platform_user for pi_name_id and datacollector_id
            #rc, tb_count = jsonSanner.get_TableCount_FromTable(json_data=json_data_table_count, table='platform_user', silent=True)
            table_length = int(tb_count)
            '''
            rc = self.MolRefAnt_DB_POstGresSQLWritter_Platform_user(file_sql,
                                                                    queryMsSQL, cursor,
                                                                    jsonfile_content_dict_lst[ifile],
                                                                    database, 'platform_user', table_length)
            '''




    if '.mgf' in filenames:
        #print("dirpath   --->: ", dirpath)
        #print("dirname   --->: ", dirname)
        print("filenames --->: ", filenames)



            #-           -
            #-      (1)-
            #- (1)     -


            rc, tb_count = queryMsSQL.query_PostGreSQL_GetTableCount(cursor=cursor,
                                                                     database=self.c.getDatabase_name(),
                                                                     schema=self.c.getDatabase_schema(),
                                                                     table='ionisation_mode', silent=True)

            print(" MolRefAnt_DB_POstGresSQLWritter_Tool +--->: ", tb_count)



            print("i_jsonfile_content_key   --> ", i_jsonfile_content_key[:])
            print("i_jsonfile_content_value --> ", i_jsonfile_content_value[:])
            print("database --> ", database)
            print("start_spectral_data_INDX --> ", start_spectral_data_INDX)




    def MolRefAnt_DB_POstGresSQLWritter_Spectral_data(self, file_hdl,
                                                      queryMsSQL, cursor,
                                                      i_jsonfile_content_dict,
                                                      i_jsonfile_content_key,
                                                      i_jsonfile_content_value,
                                                      database, table, table_length):
        __func__= sys._getframe().f_code.co_name
        rc = self.c.get_RC_SUCCESS()

        #self.m.printMesgAddStr("i_jsonfile_content_value[:]) == len(i_jsonfile_content_key[:]", self.c.getGreen(), "continuing ...")

        # check the sizes of the lists are the same, if not that is not good
        if len(i_jsonfile_content_value[:]) != len(i_jsonfile_content_key[:]):
            self.m.printMesgAddStr("i_jsonfile_content_value[:]) != len(i_jsonfile_content_key[:]", self.c.getRed(), "exiting ...")
            rc = self.c.get_RC_FAIL()
            exit(rc)

        start_spectral_data_INDX = table_length - 1  # this make sure of c++ format
        insertion_point = start_spectral_data_INDX + int(i_jsonfile_content_value[0])

        '''
        #print("i_jsonfile_content_dict --> ", i_jsonfile_content_dict['PEPMASS'])
        #print("i_jsonfile_content_key   --> ", i_jsonfile_content_key[:])
        print("i_jsonfile_content_value --> ", i_jsonfile_content_value[:])
        print("database --> ", database)
        print("schema --> ", self.c.getDatabase_schema())
        print("table --> ", table)
        print("table_length --> ", table_length)
        print("start_spectral_data_INDX --> ", start_spectral_data_INDX)
        print("insertion_point --> ", insertion_point)
        '''
        file_hdl.write("insert into\n")
        file_hdl.write("    \""+database+"\".\""+self.c.getDatabase_schema()+"\"."+table+"(\n")
        file_hdl.write("    spectral_data_id,\n")                         # TODO: ---> Done
        file_hdl.write("    feature_id,\n")                               # TODO: ---> Done
        file_hdl.write("    pepmass,\n")                                  # TODO: ---> Done
        file_hdl.write("    mslevel,\n")                                  # TODO: ---> Done
        file_hdl.write("    scan_number,\n")                              # TODO: ---> Done
        file_hdl.write("    retention_time,\n")                           # TODO: ---> Done
        file_hdl.write("    mol_json_file,\n")                            # TODO: ---> Done
        file_hdl.write("    num_peaks, peaks_list,\n")                    # TODO: ---> Done
        file_hdl.write("    ionmodechem_id,\n")                           # TODO: ---> Done
        file_hdl.write("    charge_id,\n")                                # TODO: ---> Done
        file_hdl.write("    tool_id,\n")                                  # TODO: ---> Done
        file_hdl.write("    database_id, data_id)\n")                     # TODO: ---> Done
        file_hdl.write("VALUES (\n")
        file_hdl.write(str(insertion_point)+",\n")
        file_hdl.write("'"+str(i_jsonfile_content_dict['FEATURE_ID'])+"',\n")
        file_hdl.write(str(i_jsonfile_content_dict['PEPMASS'])+",\n")
        file_hdl.write("'"+str(i_jsonfile_content_dict['MSLEVEL'])+"',\n")
        file_hdl.write("null,\n")
        file_hdl.write("null,\n")
        file_hdl.write("'"+str(i_jsonfile_content_dict['molecule_json_filename'])+"',\n")
        # NumPeaks and peak list
        file_hdl.write("null,\n")
        file_hdl.write("null,\n")
        rc, ionmodechem_id = queryMsSQL.query_GetIonModeChem_Id(cursor=cursor,
                                                                ionmodechem=i_jsonfile_content_dict['IONMODE'])
        file_hdl.write(str(ionmodechem_id)+",\n")
        # TODO: get the charge ID here from a query
        rc, charge_id = queryMsSQL.query_GetCharge_Id(cursor=cursor,
                                                      charge=i_jsonfile_content_dict['CHARGE'])
        #print("charge_id ---->: ", charge_id)
        file_hdl.write(str(charge_id)+",\n")
        # TODO: get the tool_id from a query

        rc, tool_id = queryMsSQL.query_GetTool_Id(cursor=cursor,
                                                  tool=i_jsonfile_content_dict['SOURCE_INSTRUMENT'])
        file_hdl.write(str(tool_id)+",\n")
        # TODO: get the database_id from query
        rc, database_id = queryMsSQL.query_GetDatabase_Id(cursor=cursor,
                                                          database=i_jsonfile_content_dict['database_name'])
        file_hdl.write(str(database_id)+",\n")
        # TODO: get the data_id from query
        rc, data_id = queryMsSQL.query_GetData_Id(cursor=cursor,
                                                  molecule_json_filename=i_jsonfile_content_dict['molecule_json_filename'])
        file_hdl.write(str(data_id)+"\n")

        file_hdl.write(");\n")

        return rc




            # TODO: 5. Spectral data insert table
            #rc, tb_count = jsonSanner.get_TableCount_FromTable(json_data=json_data_table_count, table='spectral_data', silent=True)
            table_length = int(tb_count) + 1
            '''
            rc = self.MolRefAnt_DB_POstGresSQLWritter_Spectral_data(file_sql,
                                                                    queryMsSQL, cursor,
                                                                    jsonfile_content_dict_lst[ifile],
                                                                    jsonfile_content_key[ifile],
                                                                    jsonfile_content_value[ifile],
                                                                    database, table, table_length)
            '''




            # TODO: 4. insert datetable for date_id insert this method into analytics_data insertion.
            '''
            rc, tb_count = jsonSanner.get_TableCount_FromTable(json_data=json_data_table_count, table='datetable', silent=True)
            table_length = cnt_date + int(tb_count)
            #print("tb_count --->: ", tb_count)
            rc = self.MolRefAnt_DB_POstGresSQLWritter_Datetable(file_sql, jsonSanner, json_data_table_count,
                                                                queryMsSQL, cursor,
                                                                jsonfile_content_dict_lst[ifile],
                                                                import_database_name,
                                                                'datetable', table_length, cnt_date)
            cnt_date += 1
            '''



    def MolRefAnt_DB_POstGresSQLWritter_Datetable(self, file_hdl, jsonSanner, json_data_table_count,
                                                  queryMsSQL, cursor,
                                                  i_jsonfile_content_dict,
                                                  database, table, table_length, cnt_date):
        __func__= sys._getframe().f_code.co_name
        rc = self.c.get_RC_SUCCESS()
        print("table_length before get_TableCount_FromTable datetable +---> ", table_length)

        rc, tb_count = jsonSanner.get_TableCount_FromTable(json_data=json_data_table_count, table=table, silent=True)
        #print("int(tb_count) after get_TableCount_FromTable datetable  +---> ", int(tb_count))
        msg = str(i_jsonfile_content_dict['molecule_json_filename'])
        #print(msg)
        filename_timestamp = time.ctime(os.path.getctime(msg))
        #msg = "        \"" + "timestamp_json_file"           + "\": \"" + filename_timestamp + "\",\n"
        #print(msg)

        rc, date_id = queryMsSQL.query_GetDate_Id(cursor=cursor, timestamp=filename_timestamp)
        print("table_length Datetable date_id +---> ", date_id)
        #rc, date_id = queryMsSQL.query_GetDate_Id(cursor=cursor,
        #                                          timestamp=i_jsonfile_content_dict['timestamp_mgf_file'])
        #print("i_jsonfile_content_dict['timestamp_mgf_file'] --->: ", i_jsonfile_content_dict['timestamp_mgf_file'])
        #print("date_id --->: ", date_id)
        if date_id == 0:
            # TODO: need to fix the analytics_data_id on the second program call
            rc, analytics_data_id = queryMsSQL.query_GetDate_analytics_data_Id(cursor=cursor,
                                                                               analytics_data=str(cnt_date))
            print("table_length Datetable analytics_data_id +---> ", analytics_data_id)
            if analytics_data_id == 0:
                insertion_point = table_length + 1
                print("table_length Datetable insertion_point +---> ", insertion_point)
                file_hdl.write("insert into\n")
                file_hdl.write("    \""+self.c.getDatabase_name()+"\".\""+self.c.getDatabase_schema()+"\"."+table+"(\n")
                file_hdl.write("    date_id,\n")                        # TODO: ---> Done
                file_hdl.write("    date_column,\n")                    # TODO: ---> Done
                file_hdl.write("    time_column,\n")                    # TODO: ---> Done
                file_hdl.write("    timestamp_with_tz_column,\n")       # TODO: ---> Done
                file_hdl.write("    analytics_data_id)\n")              # TODO: ---> Done
                file_hdl.write("VALUES (\n")
                file_hdl.write(str(insertion_point)+",\n")
                date_column = str(i_jsonfile_content_dict['json_creation_timestamp']).split('_')[0]
                file_hdl.write("'"+date_column+"',\n")
                time_column = str(i_jsonfile_content_dict['json_creation_timestamp']).split('_')[1]
                file_hdl.write("'"+time_column+"',\n")
                time_stamp = str(i_jsonfile_content_dict['json_creation_timestamp'])
                file_hdl.write("'"+time_stamp+"',\n")
                rc, analytics_data_id = queryMsSQL.query_GetAnalytics_data_Id(cursor=cursor, molecule_json_filename=i_jsonfile_content_dict['molecule_json_filename'])
                if analytics_data_id == 0:
                    file_hdl.write(str(1)+"\n")
                else:
                    file_hdl.write(str(analytics_data_id)+"\n")
                file_hdl.write(");\n")
                # inserting a line for clarity
                file_hdl.write("\n")
                #-------------------------------------------------------------------
                # [MSG-Creator]
                #-------------------------------------------------------------------
                msg = ("insert into \""+self.c.getDatabase_name()+"\".\""+self.c.getDatabase_schema()+"\"."+table+"(" +
                       "date_id, date_column, time_column, timestamp_with_tz_column, analytics_data_id)" +
                       " VALUES " +
                       "("+str(insertion_point)+","+"'"+date_column+"', "+"'"+time_column+"', "+
                       "'"+time_stamp+"', " +
                       "'"+str(analytics_data_id)+"'"+");\n")
                # Pushing to database
                rc = self.MolRefAnt_DB_POstGresSQLPusher(queryMsSQL=queryMsSQL, cursor=cursor, push_request=msg)
            # [end-if] if analytics_data_id == 0:
        # [end-if] if date_id == 0:

        return rc



            # TODO: 4. insert datetable for experiment and experimenting
            '''
            rc, tb_count = jsonSanner.get_TableCount_FromTable(json_data=json_data_table_count, table='experiment', silent=True)
            #table_length = int(tb_count)
            table_length = cnt_experiment + int(tb_count)
            print("cnt_experiment --->: ", cnt_experiment)
            rc = self.MolRefAnt_DB_POstGresSQLWritter_Experiment(file_sql, jsonSanner, json_data_table_count,
                                                                 queryMsSQL, cursor,
                                                                 jsonfile_content_dict_lst[ifile],
                                                                 'experiment', table_length)
            cnt_experiment += 1
            '''

            rc = self.MolRefAnt_DB_POstGresSQLWritter_Experimenting(file_hdl, insertion_point,
                                                                    queryMsSQL, cursor,
                                                                    i_jsonfile_content_dict,
                                                                    'experimenting', table_length)


    def MolRefAnt_DB_POstGresSQLWritter_Experimenting(self, file_hdl, insertion_point,
                                                      queryMsSQL, cursor,
                                                      i_jsonfile_content_dict,
                                                      table, table_length):




        __func__= sys._getframe().f_code.co_name
        rc = self.c.get_RC_SUCCESS()

        '''
        create table if not exists
        "MolRefAnt_DB_PostGreSQL"."MolRefAnt_DB".Experimenting(
        experiment_id INT,
        analytics_data_id INT,
        PRIMARY KEY(experiment_id, analytics_data_id),
        FOREIGN KEY(experiment_id) REFERENCES "MolRefAnt_DB_PostGreSQL"."MolRefAnt_DB".Experiment(experiment_id),
        FOREIGN KEY(analytics_data_id) REFERENCES "MolRefAnt_DB_PostGreSQL"."MolRefAnt_DB".Analytics_data(analytics_data_id)
        );
        '''


        return rc


            #-------------------------------------------------------------------
            # [Analysing]
            #-------------------------------------------------------------------
            rc, tool_id = queryMsSQL.query_GetTool_Id(cursor=cursor, tool=i_jsonfile_content_dict['SOURCE_INSTRUMENT'])
            msg = ("insert into \""+self.c.getDatabase_name()+"\".\""+self.c.getDatabase_schema()+"\"."+"Analysing"+"(" +
                   "tool_id, analytics_data_id)" +
                   " VALUES " +
                   "("+str(tool_id)+", "+str(insertion_point)+");\n")

            rc = self.MolRefAnt_DB_POstGresSQLPusher(queryMsSQL=queryMsSQL, cursor=cursor, push_request=msg)





        print(" return value +--->: analytics_data_id", analytics_data_file_id)
        print(" return value +--->: number_scans", number_scans)
        print("i_jsonfile_content_dict['IONMODE'] +--->: ", i_jsonfile_content_dict['IONMODE'])
        print(" ionisation_mode +---->: ", get_positivity())
        print(" ionisation_mode_id +---->: ", ionisation_mode_id)

        print()




print('sqlCTFFileList['+str(ifile)+'] ----> ', import_database_name)
            print('self.c.getDatabase_path() ----> ', self.c.getDatabase_path())
            # print("tb_count --->: ", tb_count)




        file_hdl.write("    pi_name_id,\n")                               # TODO: ---> Done
        file_hdl.write("    data_collector_id,\n")                        # TODO: ---> Done


        # TODO: insert the PI into the table then get its ID if not present insert into database
        rc, pi_name_id = queryMsSQL.query_GetPlatform_user_Id(cursor=cursor,
                                                              name=i_jsonfile_content_dict['PI'])
        #print("pi_name_id ---->: ", pi_name_id)
        file_hdl.write(str(pi_name_id)+",\n")
        # TODO: insert the datacollector into the platform_user table then get its ID
        rc, data_collector_id = queryMsSQL.query_GetPlatform_user_Id(cursor=cursor,
                                                                     name=i_jsonfile_content_dict['DATACOLLECTOR'])
        file_hdl.write(str(data_collector_id)+",\n")


        print("i_jsonfile_content_dict['mol_num'] ---> ", int(i_jsonfile_content_dict['mol_num']))
        print("int(i_jsonfile_content_value[0] ---->: ", int(i_jsonfile_content_value[0]))




        print(len(Json_Mol_FileList[:]))
        print(len(jsonfile_content_dict_lst[:]))





            rc = self.ctfSSQLWritter(file_sql, jsonfile_content[ifile],
                                     database, table, table_length)


        '''
        m.printMesgStr("Check/Create      : ", c.getMagenta(), str(c.getDataProcInterCom()).strip() )
        if os.path.exists(str(c.getDataProcInterCom()).strip()):
            sys.path.append(str(c.getDataProcInterCom()))
            m.printMesgAddStr("  "+c.getDataProcInterCom()+" : ", c.getGreen(),"Exits nothing to do")
        else:
            m.printMesgAddStr("  "+str(c.getDataProcInterCom())+" : ", c.getRed(),"Does not Exits we will create it...")
            os.mkdir(c.getDataProcInterCom())
            m.printMesgAddStr("                   : ", c.getGreen(),"Done.")
            sys.path.append(c.getDataProcInterCom())
        '''




        print(" tb_count --->: ", tb_count)
        print(c.getDatabase_name())
        print(c.getDatabase_schema())
        print(c.getDatabase_port())
        print(c.getDatabase_name())
        print(c.getDatabase_schema())
        print(c.getDatabase_port())
        print(JsonMoleculeFileList)
        print(" json_data_table_count --->: ", json_data_table_count)
        print("json_table_file ---> ", json_table_file)

        table_length = int(CTFDetailsKrios1Table_count)+1
        rc, sqlCTFFileList = mssqlLauncher.ctfSQLUpdaterInsertors(JsonCTFFileList=JsonMoleculeFileList,
                                                                  jsonfile_content=jsonfile_content_value_lst,
                                                                  sql_dir=sql_dir,
                                                                  table_length=table_length)

        print("json_data_table_count -->: ", json_data_table_count[:])
        print(type(json_data_table_count))
        print(len(json_data_table_count))
        print(json_data_table_count[0]['datetable'])
        print("value - ", value)
        #print(json_data_table_count['datetable'])
        #print("key - ", key)
        print("json_data_table_count["+str(i)+"]:"+value+" --->: "+datetableTable_count+"\n")


value = str("["+str(self.molecules_lst[i][j]).strip().replace(' ', ', ')+"]").replace('\"','')

# print("JsonMoleculeFileList[:] ---> ", JsonMoleculeFileList[:])
                    '''
            file = open(target_file, 'r')
            FileList = file.readlines()
            for i in range(len(FileList)):
                print("FileList["+str(i)+"]: length: "+str(len(FileList[i]))+" ---> "+ FileList[i])
                list_len += 1
            '''
            '''
            lines = file.read()
            for i in range(len(lines)):
                FileList.append(lines[i].split('\n')[0].strip())
                list_len += 1
            '''


            # Windows: Get-ChildItem  E:\Json_DataBase\ | Where-Object { $_.Name -like '*emerging*' -and $_.Name -notlike '*header*' } | Select-Object -ExpandProperty Name > E:\Json_DataBase\\target_jsonfile.txt
            ls_cmd = ["Get-ChildItem  ",
                      self.c.getPool_targetdir(),
                      " | Where-Object { $_.Name -like \'*" + self.c.getDatabase_name() + "*\' -and $_.Name -notlike \'*header*\' } | Select-Object -ExpandProperty Name",
                     ">", fileout]
            CMD = ' '.join(ls_cmd)
            self.m.printMesgStr("CMD: ", self.c.get_B_Magenta(), CMD)
            #os.system('%s'%CMD)
            #powershell_cmd = "Get-ChildItem | Select-Object -ExpandProperty Name"
            # Invoke PowerShell command
            result = subprocess.run(["powershell", "", CMD] ) #, capture_output=True, text=True)
            #print(result.stdout)
            print("self.c.getPool_targetdir() --->: ", self.c.getPool_targetdir())
            all_files_lst = [f for f in os.listdir("E://Json_DataBase//") if os.path.isfile(f)]
            print(" --->: ", all_files_lst[:])


            msg =  '\'C:\\Users\Frederic\AppData\Local\Programs\PyCharm Professional\plugins\python\helpers\pycharm\django_manage.py\' inspectdb '+ \
                   table_list[i] + ' C:/Users/Frederic/OneDrive/UVPD-Perpignan/SourceCodes/PycharmProjects/MolRefAnt_DB_Django' # + \
            #' >> '+ \
            #self.c.getJSon_TableCounts_Dir()+os.path.sep+"alldjango_models.py"
            #print("msg --->: ", msg)
            #os.system('python %s'%msg)







        self.cursor.execute("select * from \"MolRefAnt_DB_PostGreSQL\".\"MolRefAnt_DB\".analytics_data;")
        data_analytics_data = self.cursor.fetchone()

        self.cursor.execute("select * from \"MolRefAnt_DB_PostGreSQL\".\"MolRefAnt_DB\".datetable;")
        data_datetable = self.cursor.fetchone()

        print("data_analytics_data ---> ", data_analytics_data)
        print("data_datetable      ---> ", data_datetable)

        #conn.close()
        cnxn.close()

        #exit(0)






        for i in range(len(self.molecules_lst[:])):
            #self.m.printMesgAddStr("[molecules_lst]: mol("+str(i)+"), length("+str(len(self.molecules_lst[i]))+") --->: ",
            #                       self.c.getYellow(), self.molecules_lst[i][1])
            '''
            for j in range(len(self.molecules_lst[i][:])):
                self.m.printMesgAddStr("[molecules_lst]: mol("+str(i)+"), length("+str(len(self.molecules_lst[i][:]))+") --->: ",
                                       self.c.getYellow(), self.molecules_lst[i][j])
            '''
            self.ith_molecules_dict.clear()
            for ith_index, ith_element in enumerate(self.molecules_lst[i][:]):
                self.ith_molecules_dict[ith_index] = ith_element
            # [end-loop]
            msg = "mol("+str(i)+")"
            self.molecules_dict = {key: value for value, key in enumerate(self.molecules_lst[i][:])}
            #self.molecules_dict[msg] = self.ith_molecules_dict
        # [end-loop]

        print("self.ith_molecules_dict ---> ", self.ith_molecules_dict)
        print("self.molecules_dict     ---> ", self.molecules_dict)




            for i in range(database_file_len):
                if start_key in lines[i].split('\n')[0]:
                    self.ith_molecules_lst.append(lines[i].split('\n')[0])
                    if end_key in lines[i].split('\n')[0]:
                        self.molecules_lst.append(self.ith_molecules_lst[:])
                        self.ith_molecules_lst.clear()
                        break






        #print("spectrum[:]) ---> : ", spectrum[:])
        #print("mz_I_Rel[:] --->: ", mz_I_Rel[:])
        #print("mz_I_Rel_sorted[] --->: ", mz_I_Rel_sorted[:])



        print(rawfile_path + " " + self.c.getRawfile_path())
        print(rawfile_full_path_no_ext+" "+ self.c.getRawfile_full_path_no_ext() )



        print(mz_I_Rel_sorted[0])
        print(mz_I_Rel.index(mz_I_Rel_sorted[0]))
        print(spectrum[mz_I_Rel.index(mz_I_Rel_sorted[0])+5])
        print(spectrum.index(  spectrum[mz_I_Rel.index(mz_I_Rel_sorted[0])+5])   )



    if args['--cryo_em'] == True:
        version = src.PythonCodes.DataManage_common.DataManage_version()
    if args['--spectroscopy'] == True:
        version = src.PythonCodes.DataManage_common.MolRefAnt_version()


BEGIN IONS
PEPMASS=371.101196289063
CHARGE=1
MSLEVEL=2
Title: Scan#: 2880, RT: 13.343552 min
53.370948791503906 3543.15185546875
58.52656555175781 3443.591796875
61.01050567626953 38799.90234375
61.08038330078125 3710.74658203125
62.98991394042969 8392.2451171875
73.04691314697266 702726.3125
73.68528747558594 3755.27490234375
75.02616119384766 27161.1328125
79.0208969116211 6511.146484375
91.05750274658203 838079.125
93.03697204589844 5819.48828125
114.07355499267578 100271.6953125
119.08766174316406 5105.83447265625
123.30328369140625 4028.0693359375
138.8660888671875 4587.61962890625
149.04486083984375 22027.201171875
166.08094787597656 4295.85888671875
167.05567932128906 45617.46875
169.03411865234375 8226.5732421875
225.04324340820312 9990.484375
266.999755859375 40469.87890625
268.9786682128906 171044.890625
270.9577331542969 5272.8466796875
281.0516052246094 19119.337890625
283.0309753417969 37427.2890625
285.0101623535156 672931.0
299.06201171875 106169.3984375
303.0203552246094 29062.958984375
355.0705871582031 665722.0625
371.1006164550781 63353.44921875
371.1656188964844 6792.837890625
371.2807922363281 6239.44873046875
373.08282470703125 31441.638671875
393.37335205078125 4548.09619140625
END IONS







Scan Number	m/z	Intensity	Relative	Segment Number	Flags
2884	73.0469436645508	807926.25	100	1
2884	355.070739746094	799585.5625	98.9676424673663	1
2884	285.010406494141	674658.75	83.5049919469754	1
2884	91.0575485229492	672627.5625	83.2535844082303	1
2884	268.979370117188	127512.90625	15.7827408442293	1
2884	114.073608398438	76376.296875	9.45337484392913	1
2884	266.9990234375	47313.796875	5.85620245350365	1
2884	373.081390380859	40146.421875	4.96907011933329	1
2884	355.281951904297	31424.400390625	3.88951347856627	1
2884	61.0106430053711	15843.3505859375	1.9609897049313	1
2884	75.0261764526367	12276.154296875	1.51946471560678	1
2884	303.021423339844	11916.3173828125	1.47492637883872	1
2884	73.040901184082	9135.796875	1.13077114093025	1	E
2884	73.0512924194336	8499.7216796875	1.05204177728939	1	E
2884	62.9897880554199	8356.763671875	1.03434733948488	1
2884	339.039306640625	7692.876953125	0.952175641418385	1
2884	96.0858993530273	7486.27783203125	0.926604109227946	1
2884	81.0006408691406	7092.5283203125	0.877868285664997	1
2884	246.480117797852	6998.67138671875	0.866251268196664	1
2884	73.5681228637695	6863.21826171875	0.84948573730817	1
2884	166.444671630859	6476.9228515625	0.801672535279365	1
2884	170.348892211914	6419.62548828125	0.794580630135641	1
2884	63.1329879760742	6312.1240234375	0.781274778909276	1
2884	91.8839950561523	6275.2783203125	0.776714250875312	1
2884	139.392669677734	6197.7861328125	0.767122758149336	1
2884	267.795837402344	6076.77392578125	0.752144632728699	1
2884	133.009857177734	6064.5810546875	0.750635476281096	1
2884	112.587326049805	6035.998046875	0.747097652400204	1
2884	56.1290855407715	5407.029296875	0.669247879602253	1
2884	63.7651786804199	5338.28076171875	0.660738620847974	1
2884	114.068099975586	5090.88623046875	0.630117690874477	1




   self.m_on_Z.append(float(spectrum[i].split(' ')[0]))
  self.intensity.append(float(spectrum[i].split(' ')[1]))



# Now that we have separated and obtained the min and max of the spectrum
self.sorted_intensity = self.intensity.sort()
# let's compute the relative values and mapp to the correct index values
for j in range(len(self.intensity[:])):
self.intensity_indexing.append(self.intensity.index(self.intensity[j]))
self.relative.append((float(self.intensity[j] / float(self.sample_max)))*100.0)

print("self.intensity[:]", self.intensity[:])
print("self.sorted_intensity[:]", self.sorted_intensity)
print("self.intensity_indexing[:]", self.intensity_indexing[:])
print("self.relative[:]", self.relative[:])


            msg = str(self.mz_intensity_relative_sorted_lst[i][0]) + self.c.getBlue() + " <---> " + \
                  self.c.getRed() + str(self.mz_intensity_relative_sorted_lst[i][1]) + self.c.getBlue() + " <---> " + \
                  self.c.getGreen() + str(self.mz_intensity_relative_sorted_lst[i][2]) + self.c.get_C_Reset()

print("sorted_spec[:][2]", sorted_spec[2][:])
   for item in sorted_spec[:]:
   print(item[2])



            #print("list["+str(i)+"] ---> ", msg)
            #self.intensity_indexing.append(spectrum.index(spectrum[i]))

        #print("self.spectrum_out[:]", self.mz_intensity_relative_lst[:])
        #print("\n")
        #print("self.sorted_spectrum_out[:]", self.mz_intensity_relative_sorted_lst[:])


            print("begin_ions = ", begin_ions)
            print("pepmass = ", pepmass)
            print("charge  = ", charge )
            print("mslevel = ", mslevel)
            print("end_ions = ", end_ions)




print("max of the list ---> ", max(sepctrum[:].split(' ')[0]))
print("max of the list ---> ", min(sepctrum[:]))

print("sample min : ", self.sample_min)
print("sample max : ", self.sample_max)
print("sample mean : ",self.sample_mean)
print("leng of the list : ", )

self.sample_variance = numpy.var(self.intensity[:], axis=0)
print("sample variance : ",self.sample_variance)
print("The spectrum are not the same ! Continuing with the passed spectrum: ")

if scan_number == scan:
print("The scan are the same: All good")
else:
msg = self.c.getBlue()+ ""+self.c.getRed()+str(scan_number)+" != "+str(scan)
print("The scan are not the same: that is not good", msg)

print(os.getcwd())
print("The spectrum are the same !, we will use the object spectrum for now")


print("scan_number: ", scan_number)
print("RT: ", retention_time)



            for line in lines:
                spec_line = line.split('\n')[0]
                print("spec_line ---> ", spec_line)

                if trigger_key in spec_line:
                    print("line["+str(cnt)+"]- ", spec_line)
                    print(lines[cnt - 4].split('\n')[0])
                    print(lines[cnt - 3].split('\n')[0])
                    print(lines[cnt - 2].split('\n')[0])
                    print(lines[cnt - 1].split('\n')[0])
                    out_data.append(lines[cnt - 4].split('\n')[0])
                    out_data.append(lines[cnt - 3].split('\n')[0])
                    out_data.append(lines[cnt - 2].split('\n')[0])
                    out_data.append(lines[cnt - 1].split('\n')[0])




            if spec_line == end_key: break
                #if cnt == 50: break
                cnt += 1




            new_element = False
            trigger_exists = False
            out_data = ''
            element_data = ''
            for line in lines:
                if not new_element and start_key == line[:len(start_key)].lower():
                    new_element = True
                    element_data += f'{line}\n'
                else:
                    element_data += f'{line}\n'
                    if trigger_key == line[:len(trigger_key)].lower():
                        trigger_exists = True
                    if end_key == line[:len(end_key)].lower():
                        if trigger_exists:
                            out_data += element_data
                        trigger_exists = False
                        new_element = False
                        element_data = ''



https://stackoverflow.com/questions/67161599/extracting-specific-sections-of-text-from-simple-text-files

def parse_input(in_data):
    start_key = 'room'
    end_key = 'exit'
    trigger_key = 'service prov'
    new_element = False
    trigger_exists = False
    out_data = ''
    element_data = ''
    for line in in_data:
        if not new_element and start_key == line[:len(start_key)].lower():
            new_element = True
            element_data += f'{line}\n'
        else:
            element_data += f'{line}\n'
            if trigger_key == line[:len(trigger_key)].lower():
                trigger_exists = True
            if end_key == line[:len(end_key)].lower():
                if trigger_exists:
                    out_data += element_data
                trigger_exists = False
                new_element = False
                element_data = ''
    return out_data


  Executing

  print(parse_input(lines))
  Produces:

  room 5
  name "Ted"
  service prov 10.1
  outlet 49-50,52
  exit
  room 51
  name "Sue"
  service prov 10.2.0
  outlet 49
  exit





            print("len(lines) ---> ", len(lines))




        print("check ---> ", os.path.isfile(file_path))

        #self.m.printMesgAddStr(, self.c.getRed(), "WARNING -->: are not the same")



        print("input self.file_mgf ---> ", self.file_mgf)
        print("input mgf_file ---> ", mgf_file)
        print("input file_path ---> ", file_path)





print("File saved to: " + distr_file)


#boxScatter_file = targetdir+os.path.sep+"dose_Plots_" + filename_without_ext + ".png"


print("filename_without_ext_split[:]: ", filename_without_ext_split[:])


rc = self.get_statistics_for_list(newnumber)
        download_stat = "min: "+ str(self.sample_min)
        print("download_stat: ", download_stat)


        print(self.time[len(self.time[:])-1])

# boxScatter_file = targetdir+os.path.sep+"dose_Plots_" + self.get_filename_postfix(filename_without_ext) + ".png"


self.m.printMesgAddStr("boxScatter_file filename   --->: ", self.c.getMagenta(), boxScatter_file)

        #print("File saved to: " + boxScatter_file)

        self.m.printMesgAddStr("xaxis_[0:10]               --->: ", self.c.getMagenta(), boxScatter_file)
        print("boxScatter_file filename --->: ", boxScatter_file)


            print ("length of len(sp[:]): ", len(sp))
            print ("length of len(sp[:]): ", lines[cnt_lines])
            print("sp["+str(cnt_lines)+"]: ", sp)


                '''
                # getting the normalized number from the power
                cnt = 0
                for i in range(exp): cnt += 1
                lk = cnt - 20
                if flag == "yes":
                    abs_lk = abs(lk)
                    #7702787803638137
                    msg = ""
                    for i in range(0 , abs_lk-1): msg += "0"
                    msg = "0." + msg
                    number = msg + number
                    newnumber = float(number)
                else:
                    newnumber = float ( number * math.pow(10,lk) )
                '''


            print("len(self.rows): ", len(self.rows))


                        flag = "no"

                      #str(number).strip()    +" "+ \
                      #str(exp).strip()       +" "+ \
                      #str(newnumber).strip() +"\n"


                print("rows["+str(i)+"]: ", self.rows[i])


        print("Printing the first five rows of the csv file...")
        print("Number of columns in csv: ", self.csv_col)



        #print("with_whiel_loop ----> ", with_while_loop)
        self.m.printCMesg("with_whiel_loop ----> ", with_while_loop)


    numerical_value = float(upload_speed.split("B/s")[0])
    print("Numerical value:", numerical_value)
    #elif "s" == parts:
    print("c.getWith_while_loop()", c.getWith_while_loop())
    #---------------------------------------------------------------------------
    # Launch the Relion commands from here for the AutoPicking and the like
    #---------------------------------------------------------------------------
    #---------------------------------------------------------------------------
    # [RELION_END] end of the first iteration of the Relion
    #---------------------------------------------------------------------------
    try:
        csv_file = open(log_file, 'a')
    FileList = csv_file.read().splitlines()
    for i in range(len(FileList)):
        list_len = FileList[i].split(',')[:]
        nMPI_lst.append(float(FileList[i].split(',')[1].split('=')[1]))
        nThreads_lst.append(float(FileList[i].split(',')[2].split('=')[1]))
        time_lst.append(float(FileList[i].split(',')[3].split('=')[1]))
    except IOError:
    rc = c.get_RC_FAIL()
    m.printCMesg("Cannot open or no such file : "+csv_file, c.get_B_Red())
    DataManage_common.getFinalExit(c,m,rc)
    exit(rc)
    
    
    #print("upload    Numerical value:", upload_value, "Unit:", upload_unit)
    #print("Downsload Numerical value:", download_value, "Unit:", download_unit)
    #print("upload    MBs            :", upload_MBs, "MB/s")
    #print("Downsload MBs            :", download_MBs, "MB/s")
    #print(df.to_string())
    
    
    #print("upload    Numerical value:", upload_value, "Unit:", upload_unit)
    #print("Downsload Numerical value:", download_value, "Unit:", download_unit)
    #print("upload    MBs            :", upload_MBs, "MB/s")
    #print("Downsload MBs            :", download_MBs, "MB/s")
    #print(df.to_string())
